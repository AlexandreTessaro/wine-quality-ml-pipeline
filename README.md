# ğŸ· Pipeline de Machine Learning - PrevisÃ£o de Qualidade de Vinhos

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3.2-orange.svg)](https://scikit-learn.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

Projeto completo de Machine Learning para classificaÃ§Ã£o de qualidade de vinhos utilizando pipeline de dados profissional, mÃºltiplos algoritmos e deploy em produÃ§Ã£o.

---

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#-visÃ£o-geral)
- [DomÃ­nio do Problema](#-domÃ­nio-do-problema)
- [Pipeline de Dados](#-pipeline-de-dados)
- [Modelos Implementados](#-modelos-implementados)
- [Resultados](#-resultados)
- [Deploy](#-deploy)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Como Executar](#-como-executar)
- [Tecnologias](#-tecnologias)

---

## ğŸ¯ VisÃ£o Geral

Este projeto implementa um **pipeline completo de Machine Learning** para prever a qualidade de vinhos (tintos e brancos) com base em caracterÃ­sticas fÃ­sico-quÃ­micas mensurÃ¡veis. O sistema utiliza arquitetura **Data Lakehouse** para processamento de dados e implementa trÃªs algoritmos diferentes de classificaÃ§Ã£o.

### CaracterÃ­sticas Principais

- âœ… Pipeline ETL completo (Bronze â†’ Silver â†’ Gold)
- âœ… 3 algoritmos de Machine Learning implementados
- âœ… AvaliaÃ§Ã£o com 3 mÃ©tricas diferentes
- âœ… Deploy profissional usando Pickle e Joblib
- âœ… DocumentaÃ§Ã£o completa e cÃ³digo organizado
- âœ… VisualizaÃ§Ãµes e grÃ¡ficos de resultados

---

## ğŸ‡ DomÃ­nio do Problema

### PrevisÃ£o de Qualidade de Vinhos

**Tipo de Problema**: ClassificaÃ§Ã£o Multiclasse (0-10)

**Objetivo**: Desenvolver um modelo preditivo que classifique a qualidade de vinhos com base em caracterÃ­sticas fÃ­sico-quÃ­micas mensurÃ¡veis.

**AplicaÃ§Ã£o PrÃ¡tica**: 
- Auxiliar produtores e enÃ³logos na identificaÃ§Ã£o de fatores que influenciam a qualidade
- Otimizar processos de produÃ§Ã£o
- Padronizar avaliaÃ§Ãµes de qualidade
- Reduzir custos e melhorar produtos finais

**Dataset**: 
- **Fonte**: UCI Machine Learning Repository
- **Vinhos Tintos**: 1.599 registros
- **Vinhos Brancos**: 4.898 registros
- **Total**: 6.497 registros brutos

**VariÃ¡veis**:
- **Features de Entrada (14 variÃ¡veis)**:
  - Acidez fixa, acidez volÃ¡til, Ã¡cido cÃ­trico
  - AÃ§Ãºcar residual, cloretos
  - DiÃ³xido de enxofre livre e total
  - Densidade, pH, sulfatos, Ã¡lcool
  - Tipo de vinho (tinto/branco)
  - Features derivadas: acidez total, relaÃ§Ã£o Ã¡lcool/acidez
  
- **VariÃ¡vel Alvo**: Qualidade do vinho (escala 0-10)

---

## ğŸ”„ Pipeline de Dados

O pipeline segue a arquitetura **Data Lakehouse** com trÃªs camadas:

### Camada Bronze (Raw) - ExtraÃ§Ã£o
- **Fonte**: UCI Machine Learning Repository
- **Processo**: Download e armazenamento de dados brutos
- **Arquivos**: 
  - `winequality-red-raw.csv` (1.599 registros)
  - `winequality-white-raw.csv` (4.898 registros)

### Camada Silver (Processed) - TransformaÃ§Ã£o
- **UniÃ£o de datasets**: CombinaÃ§Ã£o de vinhos tintos e brancos
- **Limpeza**: RemoÃ§Ã£o de valores faltantes e duplicatas
- **Tratamento de outliers**: MÃ©todo IQR (Interquartile Range)
- **Feature Engineering**: 
  - `total_acidity` = acidez fixa + acidez volÃ¡til
  - `alcohol_acidity_ratio` = Ã¡lcool / acidez total
- **CodificaÃ§Ã£o**: ConversÃ£o de variÃ¡veis categÃ³ricas
- **Resultado**: 3.812 registros limpos e processados

### Camada Gold (Curated) - PreparaÃ§Ã£o para ML
- **SeparaÃ§Ã£o**: Features (X) e Target (y)
- **DivisÃ£o**: Treino (80%) e Teste (20%) com estratificaÃ§Ã£o
- **NormalizaÃ§Ã£o**: StandardScaler (mÃ©dia=0, desvio padrÃ£o=1)
- **Resultado Final**:
  - Treino: 3.049 amostras
  - Teste: 763 amostras
  - Features: 14 variÃ¡veis

### EstatÃ­sticas do Pipeline

| Etapa | Registros | AÃ§Ã£o |
|-------|-----------|------|
| Bronze (Raw) | 6.497 | ExtraÃ§Ã£o inicial |
| ApÃ³s uniÃ£o | 6.497 | CombinaÃ§Ã£o datasets |
| ApÃ³s remoÃ§Ã£o duplicatas | 5.320 | -1.177 duplicatas |
| ApÃ³s remoÃ§Ã£o outliers | 3.812 | -1.508 outliers |
| Gold (Treino) | 3.049 | 80% dos dados |
| Gold (Teste) | 763 | 20% dos dados |

---

## ğŸ¤– Modelos Implementados

Foram implementados e avaliados **trÃªs algoritmos diferentes** de Machine Learning:

### 1. Random Forest Classifier
- **Tipo**: Ensemble de Ã¡rvores de decisÃ£o
- **HiperparÃ¢metros**:
  - `n_estimators=100`
  - `max_depth=20`
  - `min_samples_split=5`
  - `min_samples_leaf=2`
- **Vantagens**: Robusto a outliers, reduz overfitting
- **ValidaÃ§Ã£o Cruzada**: 0.5458 (Â±0.0285)

### 2. Support Vector Machine (SVM)
- **Tipo**: Classificador baseado em kernels
- **HiperparÃ¢metros**:
  - `kernel='rbf'` (Radial Basis Function)
  - `C=1.0`
  - `gamma='scale'`
- **Vantagens**: Boa performance em problemas nÃ£o-lineares
- **ValidaÃ§Ã£o Cruzada**: 0.5451 (Â±0.0528)

### 3. Gradient Boosting Classifier
- **Tipo**: Ensemble sequencial de modelos fracos
- **HiperparÃ¢metros**:
  - `n_estimators=100`
  - `learning_rate=0.1`
  - `max_depth=5`
- **Vantagens**: Aprende com erros anteriores, boa performance
- **ValidaÃ§Ã£o Cruzada**: 0.5326 (Â±0.0392)

---

## ğŸ“Š Resultados

### MÃ©tricas de AvaliaÃ§Ã£o

Foram utilizadas **trÃªs mÃ©tricas** para avaliar o desempenho dos modelos:

#### 1. Accuracy (AcurÃ¡cia)
- **DefiniÃ§Ã£o**: ProporÃ§Ã£o de previsÃµes corretas
- **FÃ³rmula**: `Accuracy = (TP + TN) / (TP + TN + FP + FN)`
- **Quando usar**: Problemas com classes balanceadas

#### 2. Precision (PrecisÃ£o)
- **DefiniÃ§Ã£o**: ProporÃ§Ã£o de verdadeiros positivos entre todos os positivos previstos
- **FÃ³rmula**: `Precision = TP / (TP + FP)`
- **Quando usar**: Quando falsos positivos sÃ£o custosos

#### 3. F1-Score
- **DefiniÃ§Ã£o**: MÃ©dia harmÃ´nica entre Precision e Recall
- **FÃ³rmula**: `F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)`
- **Quando usar**: Balancear Precision e Recall

### Resultados dos Modelos

| Modelo | Accuracy | Precision | F1-Score | Melhor em |
|--------|----------|-----------|----------|-----------|
| **SVM** | **0.5714** | **0.5490** | 0.5306 | Accuracy e Precision |
| **Random Forest** | 0.5675 | 0.5357 | **0.5365** | F1-Score |
| **Gradient Boosting** | 0.5334 | 0.5116 | 0.5118 | - |

### AnÃ¡lise dos Resultados

#### ğŸ† Modelo Vencedor: **SVM**
- Melhor **Accuracy**: 57.14%
- Melhor **Precision**: 54.90%
- Desempenho consistente em todas as mÃ©tricas

#### ğŸ“ˆ Insights
- **Desempenho**: Valores de 53-57% sÃ£o esperados para classificaÃ§Ã£o multiclasse
- **ConsistÃªncia**: Modelos apresentam resultados similares, indicando robustez
- **Classes**: Melhor desempenho nas classes 5, 6 e 7 (mais frequentes)
- **Desafio**: Dificuldade em prever classes raras (3, 4, 8, 9)

### VisualizaÃ§Ãµes

O projeto gera automaticamente grÃ¡ficos de anÃ¡lise:

#### ğŸ“‰ ComparaÃ§Ã£o de MÃ©tricas
**Arquivo**: `results/metric_comparison.png`

GrÃ¡fico de barras comparando Accuracy, Precision e F1-Score dos trÃªs modelos.

![ComparaÃ§Ã£o de MÃ©tricas](results/metric_comparison.png)

#### ğŸ“Š Matrizes de ConfusÃ£o
**Arquivo**: `results/confusion_matrices.png`

Matrizes de confusÃ£o para cada modelo, mostrando a distribuiÃ§Ã£o de erros por classe.

![Matrizes de ConfusÃ£o](results/confusion_matrices.png)

> ğŸ’¡ **Dica**: Visualize os grÃ¡ficos executando o script de avaliaÃ§Ã£o ou abrindo os arquivos PNG na pasta `results/`

### DistribuiÃ§Ã£o das Classes

A qualidade dos vinhos no dataset processado segue a seguinte distribuiÃ§Ã£o:

| Qualidade | Quantidade | Percentual |
|-----------|------------|------------|
| 3 | 11 | 0.3% |
| 4 | 114 | 3.0% |
| 5 | 1.107 | 29.0% |
| 6 | 1.749 | 45.9% |
| 7 | 701 | 18.4% |
| 8 | 125 | 3.3% |
| 9 | 5 | 0.1% |

**ObservaÃ§Ã£o**: Dataset desbalanceado, com predominÃ¢ncia das classes 5, 6 e 7.

---

## ğŸš€ Deploy

O deploy foi realizado utilizando **duas tÃ©cnicas de serializaÃ§Ã£o**:

### Pickle
- Biblioteca padrÃ£o do Python
- CompatÃ­vel com todas as versÃµes
- Arquivos maiores (ex: Random Forest = 11.90 MB)

### Joblib â­ Recomendado
- Otimizado para arrays NumPy
- Melhor compressÃ£o (ex: Random Forest = 2.35 MB)
- Mais rÃ¡pido para modelos scikit-learn
- **Recomendado para produÃ§Ã£o**

### Arquivos Deployados

```
deploy/
â”œâ”€â”€ random_forest_pickle.pkl      (11.90 MB)
â”œâ”€â”€ random_forest_joblib.pkl      (2.35 MB) â­
â”œâ”€â”€ svm_pickle.pkl                (0.56 MB)
â”œâ”€â”€ svm_joblib.pkl                (0.16 MB) â­
â”œâ”€â”€ gradient_boosting_pickle.pkl  (2.26 MB)
â”œâ”€â”€ gradient_boosting_joblib.pkl   (0.72 MB) â­
â””â”€â”€ DEPLOYMENT_GUIDE.md           (Guia completo)
```

### ComparaÃ§Ã£o Pickle vs Joblib

| Modelo | Pickle | Joblib | ReduÃ§Ã£o |
|--------|--------|--------|---------|
| Random Forest | 11.90 MB | 2.35 MB | **80%** |
| SVM | 0.56 MB | 0.16 MB | **71%** |
| Gradient Boosting | 2.26 MB | 0.72 MB | **68%** |

### Como Usar o Modelo Deployado

```python
import joblib
import pandas as pd

# Carregar modelo
package = joblib.load('deploy/svm_joblib.pkl')
model = package['model']
scaler = package['scaler']

# Preparar dados (mesma ordem do treinamento)
features = pd.DataFrame({
    'fixed acidity': [7.4],
    'volatile acidity': [0.7],
    'citric acid': [0.0],
    'residual sugar': [1.9],
    'chlorides': [0.076],
    'free sulfur dioxide': [11.0],
    'total sulfur dioxide': [34.0],
    'density': [0.9978],
    'pH': [3.51],
    'sulphates': [0.56],
    'alcohol': [9.4],
    'total_acidity': [8.1],
    'alcohol_acidity_ratio': [1.16],
    'wine_type_encoded': [0]  # 0=tinto, 1=branco
})

# Normalizar e prever
features_scaled = scaler.transform(features)
qualidade = model.predict(features_scaled)

print(f"Qualidade prevista: {qualidade[0]}/10")
```

### DemonstraÃ§Ã£o

Execute o script de demonstraÃ§Ã£o:

```bash
python demo_deploy.py
```

Este script mostra:
- Carregamento do modelo
- PreparaÃ§Ã£o de dados de exemplo
- NormalizaÃ§Ã£o
- PrevisÃ£o de qualidade
- ComparaÃ§Ã£o entre modelos

---

## ğŸ“ Estrutura do Projeto

```
ml-pipeline/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                    # Este arquivo
â”œâ”€â”€ ğŸ“„ RELATORIO_AVALIACAO.md      # RelatÃ³rio completo da avaliaÃ§Ã£o
â”œâ”€â”€ ğŸ“„ EXEMPLO_USO.md              # Guia rÃ¡pido de uso
â”œâ”€â”€ ğŸ“„ main.py                     # Script principal (executa tudo)
â”œâ”€â”€ ğŸ“„ demo_deploy.py              # DemonstraÃ§Ã£o do deploy
â”œâ”€â”€ ğŸ“„ requirements.txt            # DependÃªncias Python
â”œâ”€â”€ ğŸ“„ .gitignore                  # Arquivos ignorados pelo Git
â”‚
â”œâ”€â”€ ğŸ“ src/                        # CÃ³digo fonte
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_pipeline.py          # Pipeline ETL (Bronze->Silver->Gold)
â”‚   â”œâ”€â”€ train_models.py           # Treinamento de 3 modelos
â”‚   â”œâ”€â”€ evaluate.py               # AvaliaÃ§Ã£o com 3 mÃ©tricas
â”‚   â””â”€â”€ deploy.py                 # Deploy (Pickle e Joblib)
â”‚
â”œâ”€â”€ ğŸ“ data/                       # Dados
â”‚   â”œâ”€â”€ raw/                      # Camada Bronze (dados brutos)
â”‚   â”‚   â”œâ”€â”€ winequality-red-raw.csv
â”‚   â”‚   â””â”€â”€ winequality-white-raw.csv
â”‚   â”œâ”€â”€ processed/                # Camada Silver/Gold (dados processados)
â”‚   â”‚   â”œâ”€â”€ winequality-processed.csv
â”‚   â”‚   â”œâ”€â”€ X_train.csv
â”‚   â”‚   â”œâ”€â”€ X_test.csv
â”‚   â”‚   â”œâ”€â”€ y_train.csv
â”‚   â”‚   â””â”€â”€ y_test.csv
â”‚   â””â”€â”€ external/                 # Dados externos
â”‚
â”œâ”€â”€ ğŸ“ models/                     # Modelos treinados
â”‚   â”œâ”€â”€ random_forest_model.pkl
â”‚   â”œâ”€â”€ svm_model.pkl
â”‚   â””â”€â”€ gradient_boosting_model.pkl
â”‚
â”œâ”€â”€ ğŸ“ results/                    # Resultados da avaliaÃ§Ã£o
â”‚   â”œâ”€â”€ metric_comparison.png     # GrÃ¡fico de comparaÃ§Ã£o
â”‚   â”œâ”€â”€ confusion_matrices.png    # Matrizes de confusÃ£o
â”‚   â””â”€â”€ model_results.csv         # Tabela de resultados
â”‚
â””â”€â”€ ğŸ“ deploy/                     # Modelos deployados
    â”œâ”€â”€ *_pickle.pkl              # VersÃµes Pickle
    â”œâ”€â”€ *_joblib.pkl              # VersÃµes Joblib â­
    â””â”€â”€ DEPLOYMENT_GUIDE.md       # Guia de uso dos modelos
```

---

## ğŸš€ Como Executar

### PrÃ©-requisitos

- Python 3.8 ou superior
- pip (gerenciador de pacotes Python)

### InstalaÃ§Ã£o

1. **Clone o repositÃ³rio** (ou baixe os arquivos)

2. **Instale as dependÃªncias**:
```bash
pip install -r requirements.txt
```

### ExecuÃ§Ã£o Completa

Execute o pipeline completo com um Ãºnico comando:

```bash
python main.py
```

Este comando executa todas as etapas:
1. âœ… Pipeline de dados (ETL)
2. âœ… Treinamento dos 3 modelos
3. âœ… AvaliaÃ§Ã£o com 3 mÃ©tricas
4. âœ… Deploy usando Pickle e Joblib

### ExecuÃ§Ã£o por Etapas

#### 1. Pipeline de Dados
```bash
python src/data_pipeline.py
```
**Resultado**: Dados processados em `data/processed/`

#### 2. Treinamento de Modelos
```bash
python src/train_models.py
```
**Resultado**: Modelos salvos em `models/`

#### 3. AvaliaÃ§Ã£o
```bash
python src/evaluate.py
```
**Resultado**: GrÃ¡ficos e tabelas em `results/`

#### 4. Deploy
```bash
python src/deploy.py
```
**Resultado**: Modelos deployados em `deploy/`

#### 5. DemonstraÃ§Ã£o
```bash
python demo_deploy.py
```
**Resultado**: DemonstraÃ§Ã£o interativa do deploy

---

## ğŸ› ï¸ Tecnologias

### Bibliotecas Principais

- **pandas** (2.1.4) - ManipulaÃ§Ã£o de dados
- **numpy** (1.26.2) - ComputaÃ§Ã£o numÃ©rica
- **scikit-learn** (1.3.2) - Machine Learning
- **matplotlib** (3.8.2) - VisualizaÃ§Ãµes
- **seaborn** (0.13.0) - GrÃ¡ficos estatÃ­sticos
- **joblib** (1.3.2) - SerializaÃ§Ã£o de modelos

### Ferramentas

- **Python** - Linguagem de programaÃ§Ã£o
- **Data Lakehouse** - Arquitetura de dados
- **Git** - Controle de versÃ£o

---

## ğŸ“ˆ PrÃ³ximos Passos

### Melhorias Sugeridas

- [ ] Tuning de hiperparÃ¢metros com GridSearch/RandomSearch
- [ ] ImplementaÃ§Ã£o de ensemble dos melhores modelos
- [ ] Deploy em ambiente cloud (AWS, GCP, Azure)
- [ ] CriaÃ§Ã£o de API REST para servir previsÃµes
- [ ] Monitoramento de performance em produÃ§Ã£o
- [ ] ImplementaÃ§Ã£o de pipeline CI/CD
- [ ] AdiÃ§Ã£o de mais features derivadas
- [ ] Tratamento especÃ­fico para classes desbalanceadas

---

## ğŸ“ Requisitos da AvaliaÃ§Ã£o

Este projeto atende aos requisitos da **AvaliaÃ§Ã£o N3**:

- âœ… **a) DomÃ­nio de problema** (1,0) - Reapresentado e documentado
- âœ… **b) Pipeline de dados** (2,0) - Data Lakehouse completo com explicaÃ§Ãµes
- âœ… **c) Treinamento e avaliaÃ§Ã£o** (5,0) - 3 modelos e 3 mÃ©tricas
- âœ… **d) Deploy** (2,0) - Pickle e Joblib implementados

**Total: 10,0 pontos**

---

## ğŸ“š DocumentaÃ§Ã£o Adicional

- **[RELATORIO_AVALIACAO.md](RELATORIO_AVALIACAO.md)** - RelatÃ³rio completo da avaliaÃ§Ã£o
- **[EXEMPLO_USO.md](EXEMPLO_USO.md)** - Guia rÃ¡pido de uso
- **[deploy/DEPLOYMENT_GUIDE.md](deploy/DEPLOYMENT_GUIDE.md)** - Guia detalhado de deploy

---

## ğŸ‘¥ Autores

Desenvolvido para a **AvaliaÃ§Ã£o N3 - Disciplina de Machine Learning**

---

## ğŸ“„ LicenÃ§a

Este projeto Ã© desenvolvido para fins educacionais.

---

## ğŸ™ Agradecimentos

- **UCI Machine Learning Repository** - Fornecimento do dataset
- **scikit-learn** - Biblioteca de Machine Learning
- Comunidade Python - Suporte e documentaÃ§Ã£o

---

<div align="center">

**ğŸ· Desenvolvido com dedicaÃ§Ã£o para classificaÃ§Ã£o de qualidade de vinhos ğŸ·**

â­ Se este projeto foi Ãºtil, considere dar uma estrela!

</div>
